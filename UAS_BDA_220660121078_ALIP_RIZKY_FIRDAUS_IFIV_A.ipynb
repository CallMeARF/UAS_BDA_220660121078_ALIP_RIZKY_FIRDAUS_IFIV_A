{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Membaca data dari file yang diunggah\n",
        "data = pd.read_csv('Reddit_Data.csv')\n",
        "\n",
        "# Menggantikan np.nan dengan string kosong ''\n",
        "data['clean_comment'].fillna('', inplace=True)\n",
        "\n",
        "# Mengambil hanya kolom 'clean_comment'\n",
        "comments = data['clean_comment'].values"
      ],
      "metadata": {
        "id": "x59jSi2g8RyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan TF-IDF untuk mengubah teks menjadi representasi numerik\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(comments).toarray()"
      ],
      "metadata": {
        "id": "Q1GsC_9y8gu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi data menjadi data latih dan data uji\n",
        "X_train, X_test, comments_train, comments_test = train_test_split(X, comments, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "7mglUDNP8zGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat model Autoencoder\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 32\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
        "decoder = Dense(input_dim, activation=\"sigmoid\")(encoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Melatih model Autoencoder\n",
        "history = autoencoder.fit(X_train, X_train, epochs=20, batch_size=256, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "id": "NdzVd6dD83iF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a9a63b-e624-445c-bdc6-91c01489f81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "94/94 [==============================] - 4s 36ms/step - loss: 0.1838 - val_loss: 0.0621\n",
            "Epoch 2/20\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0252 - val_loss: 0.0102\n",
            "Epoch 3/20\n",
            "94/94 [==============================] - 3s 29ms/step - loss: 0.0067 - val_loss: 0.0045\n",
            "Epoch 4/20\n",
            "94/94 [==============================] - 4s 46ms/step - loss: 0.0034 - val_loss: 0.0027\n",
            "Epoch 5/20\n",
            "94/94 [==============================] - 3s 29ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 6/20\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 7/20\n",
            "94/94 [==============================] - 3s 29ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 8/20\n",
            "94/94 [==============================] - 4s 38ms/step - loss: 9.4114e-04 - val_loss: 9.0324e-04\n",
            "Epoch 9/20\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 7.8372e-04 - val_loss: 7.6561e-04\n",
            "Epoch 10/20\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 6.7116e-04 - val_loss: 6.6419e-04\n",
            "Epoch 11/20\n",
            "94/94 [==============================] - 5s 49ms/step - loss: 5.8762e-04 - val_loss: 5.8656e-04\n",
            "Epoch 12/20\n",
            "94/94 [==============================] - 6s 69ms/step - loss: 5.2399e-04 - val_loss: 5.2679e-04\n",
            "Epoch 13/20\n",
            "94/94 [==============================] - 6s 59ms/step - loss: 4.7431e-04 - val_loss: 4.7935e-04\n",
            "Epoch 14/20\n",
            "94/94 [==============================] - 6s 59ms/step - loss: 4.3488e-04 - val_loss: 4.4096e-04\n",
            "Epoch 15/20\n",
            "94/94 [==============================] - 4s 38ms/step - loss: 4.0245e-04 - val_loss: 4.0920e-04\n",
            "Epoch 16/20\n",
            "94/94 [==============================] - 3s 29ms/step - loss: 3.7611e-04 - val_loss: 3.8307e-04\n",
            "Epoch 17/20\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 3.5415e-04 - val_loss: 3.6105e-04\n",
            "Epoch 18/20\n",
            "94/94 [==============================] - 3s 33ms/step - loss: 3.3576e-04 - val_loss: 3.4263e-04\n",
            "Epoch 19/20\n",
            "94/94 [==============================] - 4s 41ms/step - loss: 3.2014e-04 - val_loss: 3.2676e-04\n",
            "Epoch 20/20\n",
            "94/94 [==============================] - 3s 29ms/step - loss: 3.0686e-04 - val_loss: 3.1316e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan model untuk mendeteksi anomali\n",
        "X_train_pred = autoencoder.predict(X_train)\n",
        "mse = np.mean(np.power(X_train - X_train_pred, 2), axis=1)\n",
        "threshold = np.percentile(mse, 95)  # Menentukan threshold dari data latih\n",
        "\n",
        "X_test_pred = autoencoder.predict(X_test)\n",
        "mse_test = np.mean(np.power(X_test - X_test_pred, 2), axis=1)\n",
        "\n",
        "# Menandai anomali berdasarkan threshold\n",
        "anomalies = mse_test > threshold"
      ],
      "metadata": {
        "id": "8IZIG6ao9JNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f328c5e-fd8d-4666-fb40-02ad4e8f7b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "932/932 [==============================] - 3s 3ms/step\n",
            "233/233 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan jumlah anomali terdeteksi dengan format yang menonjol\n",
        "print(f'\\n===============================================')\n",
        "print(f' Jumlah anomali terdeteksi: {np.sum(anomalies)} ')\n",
        "print(f'===============================================\\n')\n",
        "\n",
        "# Menampilkan komentar anomali dalam tabel menggunakan tabulate\n",
        "anomalous_comments = comments_test[anomalies]\n",
        "anomalous_comments_table = pd.DataFrame(anomalous_comments[:10], columns=['Anomalous Comments'])\n",
        "\n",
        "# Menggunakan tabulate untuk tampilan tabel yang lebih baik\n",
        "table = tabulate(anomalous_comments_table, headers='keys', tablefmt='pretty', showindex=False)\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDNNtUCDCbql",
        "outputId": "0feb951f-f9aa-4be2-ed89-a2714dbdd34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===============================================\n",
            " Jumlah anomali terdeteksi: 452 \n",
            "===============================================\n",
            "\n",
            "+-------------------------------------------------------------------+\n",
            "|                        Anomalous Comments                         |\n",
            "+-------------------------------------------------------------------+\n",
            "|                                yay                                |\n",
            "|                               hell                                |\n",
            "|              bas inka yahi randi rona chalta rahega               |\n",
            "|                            disgraceful                            |\n",
            "|                         bahot hua samman                          |\n",
            "|                  sandking notice the crab claws                   |\n",
            "|                              shikari                              |\n",
            "|                              dumbass                              |\n",
            "|                             scum bag                              |\n",
            "| 孤单寂寞觉得冷 难道要刻意假装说“印度威胁到中国制造业”才叫清醒么？ |\n",
            "+-------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}